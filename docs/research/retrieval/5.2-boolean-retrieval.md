# Research Notes: Boolean Retrieval (Deep Dive) - Chapter 5.2

> **Objective**: Comprehensive technical breakdown of Boolean Retrieval, targeting advanced engineering concepts, data structures, and algorithmic optimizations found in systems like Lucene, Elasticsearch, and Tantivy.

## 1. The Physical Anatomy of an Inverted Index
At its core, the Inverted Index is a mechanism to invert the `Document -> Terms` relationship into `Term -> Documents`. However, the physical layout is far more complex than a simple Hash Map.

### 1.1 The Dictionary (Term Dictionary)
The dictionary maps a `Term` (string) to a `Pointer` (file offset) where the Postings List begins.
**Requirements**:
-   **Lookup Speed**: Must definitely be faster than $O(N)$.
-   **Memory Overhead**: Should ideally fit in RAM (or mostly in RAM).
-   **Prefix Support**: Needs to support `run*` or `*ing`.

**Data Structures**:
1.  **Hash Map**:
    -   *Pros*: $O(1)$ lookup.
    -   *Cons*: No prefix support. High memory overhead for collision handling. Unsorted (cannot iterate keys).
2.  **Binary Search Tree (BST)**:
    -   *Pros*: Order-preserving.
    3.  *Cons*: $O(log N)$ is slower than Hash. Cache-unfriendly pointer chasing.
3.  **FST (Finite State Transducer)** - *The Industry Standard (Lucene)*:
    -   Shared prefixes and suffixes are compressed.
    -   Example: `running`, `runner`, `run` share `run`.
    -   *Memory*: Can compress a dictionary of millions of terms into a few MBs.
    -   *Speed*: $O(L)$ where $L$ is term length. Independent of dictionary size.

### 1.2 The Postings List (Inverted List)
A sequence of integers (DocIDs).
`Term: "apple" -> [10, 24, 50, 60, ...]`

**The Sorting Constraint**:
-   Postings lists **MUST** be sorted by DocID.
-   *Why?* Enables linear-time intersection ($O(A+B)$) and delta-compression.

**Payloads**:
Often, we store more than just DocIDs.
`[DocID, Freq, [Positions], [Offsets]]`
-   **DocID**: Which document?
-   **Term Frequency (TF)**: How many times did it appear? (Crucial for BM25).
-   **Positions**: "Token 5 and Token 10". (Crucial for Phrase Search).
-   **Offsets**: Byte offsets in the raw text (Crucial for Highlighting snippets).

---

## 2. Integer Compression: The Unsung Hero
Index size matters. Raw integers (4 bytes) are wasteful.
`[1, 2, 3, ... 1,000,000]` -> 4MB of data.

### 2.1 Delta Encoding (d-gap)
Instead of storing `[10, 24, 50, 60]`, we store the *difference*:
`[10, 14, 26, 10]` (10, 10+14=24, 24+26=50, ...).
*Benefit*: smaller numbers require fewer bits.

### 2.2 VByte (Variable Byte)
-   Uses 7 bits for data, 1 bit for "continuation".
-   Small numbers (0-127) take 1 byte.
-   Larger numbers take 2+ bytes.
-   *Cons*: Branch prediction failures (CPU hates conditional loops).

### 2.3 Bit Packing & SIMD-BP128 (Frame of Reference)
-   Group 128 DocIDs into a "block".
-   Calculate the max value in that block (e.g., max delta is 500, which needs 9 bits).
-   Pack *all* 128 numbers using exactly 9 bits each.
-   **SIMD**: Modern CPUs can unpack 128 integers in a single cycle using AVX-512 instructions.
-   *Result*: Decompression speeds of 5B+ integers/sec.

---

## 3. Intersection Algorithms: The "Zipper" vs "Galloping"
Query: `blue AND sky` (Intersection of List A and List B).

### 3.1 SvS (Sort-vs-Sort) / Merge Join
Standard "Zipper" approach.
-   Pointer A at head of List A. Pointer B at head of List B.
-   Compare, verify, advance lower pointer.
-   *Best for*: Two dense lists of roughly equal size.
-   *Cost*: $O(N + M)$.

### 3.2 MaxScore / WAND (Block-Based Optimization)
Optimization for skipping chunks. If we need the top 10 results, and the current block's *maximum possible score* is lower than our 10th best hit so far, **skip the entire block**.

### 3.3 Galloping Search (Exponential Skip)
What if List A has 1M items, List B has 10?
Iterating 1M items is wasteful.
**Algorithm**:
1.  Read item from B (`val = 5000`).
2.  Perform "Galloping" on A to find 5000.
    -   Check index 1, 2, 4, 8, 16, 32... $2^k$.
    -   Once we overshoot, perform Binary Search in the mapped range.
-   *Cost*: $O(M \cdot log N)$ (where M is small list, N is large).

---

## 4. Roaring Bitmaps: The Modern Set
Sometimes we don't need frequencies/positions. We just need existence (e.g., `status=published`, `category=shoes`).
Using `int[]` is bloated. Using standard `BitSet` (00010010...) is sparse and wasteful for high DocIDs.

**Roaring Bitmaps** hybridize the approach:
-   Divide space into 65k chunks (containers).
-   **Dense Chunk (>4096 items)**: Use a Bitmap (4096 bits).
-   **Sparse Chunk (<4096 items)**: Use an Array of `short` (2 bytes).
-   **Run Container**: Run-Length Encoding for contiguous ranges (100-1000).

*Impact*: Bitwise operations (AND, OR, XOR) become blindingly fast CPU instructions. Used by Elasticsearch, Spark, Kafka.

---

## 5. Phrase Queries & Positional Logic
Query: `"to be or not to be"`
This is NOT a set intersection. It is a sequence constraint.

### 5.1 NextWord Index
Store pairs `word -> next_word`.
*Explosion via Combinatorics*: Vocabulary size squares. Not practical for general text.

### 5.2 Position Lists (Standard)
List: `to: [Doc1: 1, 4], be: [Doc1: 2, 5]`
Check:
-   Doc1 matches both? Yes.
-   Load positions.
-   Is `pos(be) == pos(to) + 1`?
    -   `2 == 1 + 1` (Match!)
    -   `5 == 4 + 1` (Match!)

### 5.3 Slovene (Span) Queries
Generalized positional logic.
`NEAR(apple, pie, slop=5)` -> "apple" within 5 words of "pie".
algorithm:
-   Find all occurrences of A.
-   Find all occurrences of B.
-   Interleave iterators to find windows satisfying `abs(posA - posB) <= 5`.

---

## 6. Failure Modes & Edge Cases
1.  **The Stop Word Problem**:
    -   Query: `the AND matrix`.
    -   `the` list has 1 billion entries. `matrix` has 10k.
    -   *Naive Zipper*: Reads 1B integers. Slow.
    -   *Optimized*: Load `matrix`. For each hit, check `the` using Skip List/Galloping. Or just ignore `the` entirely (Stop Word Removal), though this hurts precision ("To be or not to be").
2.  **Vocabulary Mismatch**:
    -   User types `cellphone`, doc has `mobile`.
    -   Boolean AND returns 0.
    -   *Fix*: Synonym Graph Filters (Inject `mobile` into the token stream of `cellphone` at the same position).

---

## 7. Wildcards and Fuzzy Search
Query: `te?t` or `test*`.

### 7.1 Permuterm Index
Store rotations of every term.
Term: `hello`
Store: `hello$`, `ello$h`, `llo$he`, `lo$hel`, `o$hel`
Query `hel*` -> rotate to `hel$*` -> lookup in B-Tree.

### 7.2 k-gram (n-gram) Index
Break terms into trigrams.
`castle` -> `$ca`, `cas`, `ast`, `stl`, `tle`, `le$`
Query `cas*` -> intersect `($ca, cas)`.
*Post-filter*: Some documents match trigrams but not the word (e.g., `castles` vs `cast`). Must verify raw term.

### 7.3 Levenshtein Automata (Fuzzy)
Query: `apple` (fuzziness 1).
Build a Finite State Automaton (DFA) representing all strings within edit distance 1 of `apple`.
Traverse the Term Dictionary (FST) with this DFA.
*Efficiently* restrict visiting branches of the dictionary that cannot possibly match.

---

## 8. Summary for the Engineer
-   **Boolean is strict**: It defines the *candidate set*.
-   **Postings are compressed**: VByte/SIMD-BP128.
-   **Intersections are optimized**: Smallest-to-largest, Galloping, Roaring Bitmaps.
-   **Positions are heavy**: Phrase searches are 10-100x more expensive than term searches.
