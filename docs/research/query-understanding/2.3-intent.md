# Research: 2.3 Intent vs Tokens

## The Fundamental Tension
Tokens are what the user typed. Intent is what they meant. These often diverge.

---

## Tokens: The Surface

### What Tokenization Does
```
"men's running shoes" → ["men's", "running", "shoes"]
"iPhone15Pro" → ["iPhone15Pro"] or ["iPhone", "15", "Pro"]?
"state-of-the-art" → ["state", "of", "the", "art"] or ["state-of-the-art"]?
```

### Tokenization Decisions Matter

| Approach | "New York City" | Trade-off |
|----------|-----------------|-----------|
| Whitespace | ["New", "York", "City"] | Loses entity |
| N-grams | ["New", "York", "City", "New York", "York City", "New York City"] | Explodes index |
| NER-aware | ["New York City"] | Requires NER model |

---

## Intent: The Depth

### Beyond Keywords

| Query | Tokens | Intent |
|-------|--------|--------|
| "cheap laptop" | ["cheap", "laptop"] | Price < $500, not "cheap" in text |
| "best phone 2024" | ["best", "phone", "2024"] | Top-rated, recent, not "best" in title |
| "running shoes" | ["running", "shoes"] | Athletic footwear for running activity |
| "apple" | ["apple"] | Could be fruit, company, or music |

---

## The Token-Intent Gap

### Case 1: Synonyms
**Query:** "couch"
**Also relevant:** "sofa", "loveseat", "settee"

Tokens match NONE of these. Intent matches ALL.

### Case 2: Hyponyms/Hypernyms
**Query:** "fruit"
**Also relevant:** "apple", "banana", "orange" (hyponyms)

**Query:** "iPhone"
**Also relevant:** "smartphone", "phone" (hypernyms)

### Case 3: Attributes in Intent
**Query:** "cheap laptop"
**Token "cheap":** looking for the literal word
**Intent "cheap":** price < $500

**Query:** "fast delivery"
**Token "fast":** the word in description
**Intent "fast":** same-day or next-day shipping

### Case 4: Negation
**Query:** "laptop without touchscreen"
**Tokens:** ["laptop", "without", "touchscreen"]
**Bad result:** Laptops WITH touchscreen (contains all tokens)
**Good result:** Laptops that don't have touchscreen

### Case 5: Context-Dependent
**Query:** "jaguar"
**In automotive context:** the car brand
**In wildlife context:** the animal
**In tech context:** Apple's macOS version

---

## Real-World Failures

### Failure 1: Token Matching Gone Wrong
**Query:** "I don't want a touchscreen laptop"
**System:** Returns touchscreen laptops (matches "touchscreen" and "laptop")
**Problem:** Ignored negation

### Failure 2: Missing Synonyms
**Query:** "sneakers"
**Catalog:** Only has "athletic shoes", "running shoes"
**Result:** Zero results
**Problem:** Synonym not mapped

### Failure 3: Over-Tokenization
**Query:** "New York pizza"
**System:** Matches products with "New" in title (e.g., "New Arrival")
**Problem:** Entity not recognized

### Failure 4: Under-Tokenization
**Query:** "iphone15promax"
**System:** No match (looking for exact string)
**Catalog:** "iPhone 15 Pro Max"
**Problem:** Not split into components

---

## Bridging the Gap

### Approach 1: Synonym Expansion
```
"couch" → "couch OR sofa OR loveseat"
```

**Pros:** Simple, interpretable
**Cons:** Manual curation, can reduce precision

### Approach 2: Semantic Search (Embeddings)
```
embed("couch") ≈ embed("sofa")  # Cosine similarity ~0.9
```

**Pros:** Automatic, handles unseen synonyms
**Cons:** Can over-generalize, black box

### Approach 3: Query Rewriting
ML model rewrites query to match catalog:
```
"cheap laptop" → "laptop price:[0 TO 500]"
```

**Pros:** Precise intent capture
**Cons:** Needs training data, error-prone

### Approach 4: Hybrid
1. First-pass: Token matching (BM25)
2. Second-pass: Semantic reranking (embeddings)
3. Fallback: Semantic retrieval if token matching fails

---

## Intent Understanding Techniques

### Entity Recognition
```
"Nike running shoes size 10" → 
{
  "brand": "Nike",
  "category": "running shoes",
  "size": "10"
}
```

### Attribute Extraction
```
"laptop under $500 with 16GB RAM" →
{
  "category": "laptop",
  "price_max": 500,
  "ram": "16GB"
}
```

### Intent Classification
```
"how to clean running shoes" → intent: "informational"
"buy running shoes" → intent: "transactional"
"Nike store near me" → intent: "local"
```

---

## The Precision-Recall Trade-off

### Pure Token Matching (High Precision)
- Only returns exact matches
- Misses synonyms, related items
- High zero-result rate
- But results are very relevant

### Pure Semantic Matching (High Recall)
- Returns anything vaguely related
- Never zero results
- But many irrelevant results
- Users have to dig through noise

### The Right Balance
```
Start strict → Fallback to broader → Never give up
```

1. Exact match (tokens)
2. Synonym expansion
3. Semantic similarity
4. "Did you mean...?"
5. Category fallback

---

## Key Takeaways

1. **Tokens ≠ Intent** — the literal words are just a hint
2. **Synonyms are table stakes** — must handle couch/sofa
3. **Negation is hard** — "without X" often returns X
4. **Context resolves ambiguity** — user history, session, location
5. **Hybrid approaches win** — tokens for precision, semantics for recall
