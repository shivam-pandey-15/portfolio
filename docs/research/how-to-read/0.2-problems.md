# Research: 0.2 Problems This Guide Solves

## The Knowledge Gap

### Problem 1: "I don't know what I don't know"
Most engineers learn search by:
1. Reading Elasticsearch docs → Know *how* to add a doc
2. Copy-pasting Stack Overflow → Know *what* worked for someone else
3. Trial and error → No systematic mental model

**This guide provides:** A structured curriculum from business problem to production system.

---

### Problem 2: "The tutorial worked, production didn't"
**Scenario:** Engineer builds search for 10K products. Works great.
Company grows to 10M products. Search breaks:
- Indexing takes 12 hours
- P99 latency is 2 seconds
- Ranking is random garbage

**Root cause:** Didn't understand:
- Sharding strategies (document vs term partitioning)
- Segment merging and refresh intervals
- Feature engineering for ranking at scale

**This guide teaches:** How to think about scale from Day 1.

---

### Problem 3: "My ML model is great but search sucks"
**Scenario:** ML team trains a state-of-the-art reranker.
- Offline NDCG: 0.85 (excellent)
- Online CTR: No improvement

**Root causes:**
1. Retrieval is broken → Model never sees the right candidates
2. Latency budget blown → Can only rerank top 10, not top 1000
3. Training data bias → Model learned from bad clicks on bad results

**This guide teaches:** End-to-end pipeline thinking, not just model training.

---

### Problem 4: "Search is slow and I don't know why"
**Scenario:** Average latency is 50ms, but P99 is 800ms.

**Potential causes (that tutorials don't cover):**
- Cold shards waking up
- Large aggregations on high-cardinality fields
- Cross-cluster fan-out timeout
- GC pauses during indexing
- Slow disk on one replica

**This guide teaches:** How to debug latency by understanding the internal architecture.

---

### Problem 5: "We keep breaking search with every release"
**Scenario:** PM says "Add this new field to ranking."
Engineer adds it. Relevance drops 20%.

**Root cause:** No:
- Offline evaluation pipeline (NDCG regression tests)
- A/B testing framework for search
- Guardrail metrics

**This guide teaches:** How to ship search changes safely.

---

## Summary: What This Guide Unlocks

| Before | After |
|--------|-------|
| "Search is a black box" | Understand every layer: Query → Retrieval → Ranking → Serving |
| "It works on my laptop" | Design for 100M docs, 10K QPS |
| "My model is accurate" | Understand where ML fits in the full pipeline |
| "I don't know why it's slow" | Systematic latency debugging |
| "We break relevance every release" | Evaluation and safe deployment |
