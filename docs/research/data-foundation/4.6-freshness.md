# 3.6 Freshness & Updates

Search users expect real-time results, but search engines are inherently "eventually consistent." Understanding this gap is crucial for building reliable systems.

---

## 1. The Freshness Expectation vs Reality

### What Users Expect:
```
T+0s:   Seller updates price from $99 to $79
T+0s:   User searches "product X"
T+0s:   User sees $79 price
```

### What Actually Happens:
```
T+0s:   Seller updates price in database
T+1s:   CDC captures change, sends to Kafka
T+2s:   Indexer consumes message
T+3s:   Document written to in-memory buffer
T+4s:   Refresh makes doc searchable    ← First visible!
T+4s:   User searches, sees $79
```

**Minimum latency:** 4 seconds (best case)
**Typical latency:** 5-30 seconds
**Worst case:** Minutes (during high load)

---

## 2. The Write Path: Deep Dive

### Step 1: In-Memory Buffer
```
Write Request arrives
      │
      ▼
┌─────────────────────┐
│  Indexing Buffer    │  ← Lives in JVM Heap
│  (10% of heap)      │     Not yet searchable
└─────────────────────┘
```

### Step 2: Transaction Log (Durability)
```
Simultaneously:
      │
      ▼
┌─────────────────────┐
│  Translog           │  ← Written to disk (fsync)
│  (append-only)      │     Survives crash
└─────────────────────┘
```

### Step 3: Refresh (Searchability)
```
Every 1 second (default):
      │
      ▼
┌─────────────────────┐
│  New Segment        │  ← Written to OS cache
│  (immutable file)   │     NOW SEARCHABLE
└─────────────────────┘
```

### Step 4: Flush (Persistence)
```
Every 30 minutes OR 512MB translog:
      │
      ▼
┌─────────────────────┐
│  Segments fsync'd   │  ← Safe on disk
│  Translog cleared   │
└─────────────────────┘
```

---

## 3. Segment Management

### The Segment Explosion Problem

**Math:**
```
Refresh interval: 1 second
Segments created: 1 per refresh
Segments per day: 86,400

With 10 shards: 864,000 segments per day!
```

**Why this is bad:**
1. Each segment = open file handle
2. Linux default ulimit: 65,536 files
3. Each search must check ALL segments
4. Query time grows linearly with segment count

### The Merge Policy

**How Lucene handles it:**
```
         Small segments
              │
              ▼
      ┌───┬───┬───┬───┐
      │ A │ B │ C │ D │  ← 4 small segments (~10MB each)
      └───┴───┴───┴───┘
              │
              │ Background merge
              ▼
         ┌─────────┐
         │   AB    │  ← 2 medium segments (~20MB each)
         ├─────────┤
         │   CD    │
         └─────────┘
              │
              │ Another merge
              ▼
         ┌─────────┐
         │  ABCD   │  ← 1 large segment (~40MB)
         └─────────┘
```

**Merge costs:**
- CPU: Reading/writing all docs
- Disk I/O: Write amplification of 5-7x
- Memory: Merge buffers

### Monitoring Segment Health

```json
// Check segment status
GET /products/_segments

// Response
{
  "indices": {
    "products": {
      "shards": {
        "0": [{
          "segments": {
            "_0": { "size_in_bytes": 50000000, "num_docs": 10000 },
            "_1": { "size_in_bytes": 45000000, "num_docs": 9500 },
            "_2": { "size_in_bytes": 1000, "num_docs": 5 },      // Tiny!
            "_3": { "size_in_bytes": 500, "num_docs": 2 },       // Tiny!
            // ... 500 more tiny segments = PROBLEM
          }
        }]
      }
    }
  }
}
```

---

## 4. Tuning for Different Workloads

### High-Throughput Ingestion (Bulk Load)

```json
// Before bulk load
PUT /products/_settings
{
  "index": {
    "refresh_interval": "-1",              // Disable refresh
    "number_of_replicas": 0,              // No replication during load
    "translog.durability": "async",       // Async fsync
    "translog.flush_threshold_size": "1gb" // Larger translog
  }
}

// After bulk load
POST /products/_refresh
PUT /products/_settings
{
  "index": {
    "refresh_interval": "1s",
    "number_of_replicas": 1,
    "translog.durability": "request"
  }
}

// Force merge to optimize
POST /products/_forcemerge?max_num_segments=1
```

**Performance comparison:**

| Setting | Throughput | Freshness |
|---------|------------|-----------|
| Default (1s refresh) | 5,000 docs/s | 1 second |
| 30s refresh | 7,500 docs/s (+50%) | 30 seconds |
| Disabled refresh | 15,000 docs/s (+200%) | Manual only |

### Real-Time Search (User-Facing)

```json
PUT /products/_settings
{
  "index": {
    "refresh_interval": "1s",              // Fast refresh
    "number_of_replicas": 1,              // For availability
    "translog.durability": "request"      // Sync writes
  }
}
```

### Log/Metrics (Append-Only)

```json
PUT /logs-2024-01/_settings
{
  "index": {
    "refresh_interval": "30s",            // Lower priority
    "number_of_replicas": 1,
    "translog.durability": "async"        // OK to lose last 5s
  }
}
```

---

## 5. Update Strategies

### Strategy 1: Full Reindex (Simple, Expensive)

```python
def full_reindex():
    """Rebuild entire index from database"""
    
    # Create new index
    new_index = f"products_v{timestamp}"
    create_index(new_index, MAPPING)
    
    # Stream all data from DB
    for batch in db.stream_all_products(batch_size=1000):
        bulk_index(new_index, batch)
    
    # Atomic switch
    switch_alias("products", new_index)
    delete_old_index()
```

**Use when:**
- Schema changes
- Analyzer changes
- < 10M documents
- Nightly job acceptable

### Strategy 2: Incremental Updates (Complex, Fast)

```python
# CDC pipeline (Debezium → Kafka → Consumer)

@kafka_consumer("product-changes")
def handle_product_change(event):
    product_id = event["id"]
    operation = event["op"]  # 'c' create, 'u' update, 'd' delete
    
    if operation == "d":
        es.delete(index="products", id=product_id)
    else:
        # Fetch full document (CDC might have partial data)
        product = db.get_product(product_id)
        enriched = enrich_product(product)  # Add brand, category names
        es.index(index="products", id=product_id, document=enriched)
```

**Challenges:**
1. **Ordering:** Events can arrive out of order
2. **Joins:** CDC captures single table, search needs denormalized
3. **Backfill:** Initial load needs different path
4. **Failures:** Event replay and idempotency

### Strategy 3: Hybrid (Industry Standard)

```
┌─────────────────────────────────────────────────────────┐
│                    HYBRID STRATEGY                       │
├─────────────────────────────────────────────────────────┤
│                                                          │
│  Real-Time Layer (CDC → Kafka → ES)                     │
│  • Price changes: < 5 seconds                           │
│  • Stock updates: < 5 seconds                           │
│  • New products: < 1 minute                             │
│                                                          │
│  + Nightly Reconciliation                               │
│  • Full reindex from DB snapshot                        │
│  • Heals any drift or missed events                     │
│  • Runs 2-5 AM when traffic is low                      │
│                                                          │
└─────────────────────────────────────────────────────────┘
```

---

## 6. Optimistic Concurrency Control

### The Lost Update Problem

```
Timeline:
T0: Doc version = 1, stock = 100
T1: User A reads doc (version 1, stock 100)
T2: User B reads doc (version 1, stock 100)
T3: User A writes (stock = 99)  → version becomes 2
T4: User B writes (stock = 99)  → OVERWRITES A's change!

Result: Should be 98, but is 99
```

### The Solution: Version Checking

```python
def safe_update(doc_id, update_fn):
    """Update with optimistic concurrency control"""
    
    max_retries = 3
    for attempt in range(max_retries):
        # Read current version
        doc = es.get(index="products", id=doc_id)
        seq_no = doc["_seq_no"]
        primary_term = doc["_primary_term"]
        
        # Apply update
        updated_doc = update_fn(doc["_source"])
        
        try:
            # Write with version check
            es.index(
                index="products",
                id=doc_id,
                document=updated_doc,
                if_seq_no=seq_no,
                if_primary_term=primary_term
            )
            return  # Success!
            
        except ConflictError:
            # Someone else updated, retry
            if attempt == max_retries - 1:
                raise
            time.sleep(0.1 * (attempt + 1))  # Backoff
```

### For High-Contention Fields: Script Updates

```json
// Instead of read-modify-write, use atomic script

POST /products/_update/prod_123
{
  "script": {
    "source": "ctx._source.stock -= params.quantity",
    "params": {
      "quantity": 1
    }
  }
}

// Runs atomically on the shard leader
// No read-modify-write race
```

---

## 7. Freshness SLA by Field Type

Not all fields need the same freshness:

| Field | Max Staleness | Strategy |
|-------|---------------|----------|
| Inventory/Stock | 5 seconds | Real-time CDC |
| Price | 5 seconds | Real-time CDC |
| Availability | 1 minute | Real-time CDC |
| New Products | 15 minutes | Near real-time |
| Title/Description | 1 hour | Batch or delayed CDC |
| Reviews/Ratings | 4 hours | Batch aggregation |
| Search Signals (CTR) | 15 minutes | Streaming aggregation |

**Architecture implication:**
```
High-freshness fields → Separate index or sidecar
Low-freshness fields → Main product index

Query combines both at search time:
Main index (content) + Sidecar (price/stock)
```
