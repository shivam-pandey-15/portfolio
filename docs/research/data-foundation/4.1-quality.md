# 3.1 Quality as a Data Problem

## The Core Thesis
Most engineering teams treat search as a **Ranking Problem** (Algorithms, Learning to Rank, Vectors).
In reality, **80% of search quality failures are Data Problems**.

> "No ranking model can fix broken data."

**The Multiplication Rule:**
```
Final_Score = DataQuality × QueryUnderstanding × RankingModel
```
If DataQuality = 0.5 (50% of data is correct), your maximum possible score is 0.5.
No amount of BERT fine-tuning can overcome garbage data.

---

## 1. The Cost of Bad Data: Real-World Examples

### Example 1: The $1.25M/day Null Price Bug
**Company**: Mid-size E-commerce (10M products)
**Bug**: 5% of products had `price: null`
**UI Behavior**: Displayed as "$0.00"
**User Behavior**: Clicked, saw real price in cart, abandoned

**The Math:**
```
Daily Traffic: 1,000,000 searches
Products with null price: 5%
Click-through on "$0.00" items: 20%
Abandonment rate when real price shown: 90%
Average Order Value: $50
Conversion Rate normally: 3%

Lost conversions = 1,000,000 × 0.05 × 0.20 × 0.90 × 0.03 × $50
               = $1,350,000 / day
```

**Fix**: Added ingestion gate that rejected products without valid price.
**Time to fix**: 2 hours of engineering.
**ROI**: $1.35M × 365 = $492M/year saved by a 2-hour fix.

---

### Example 2: The Pandemic Mask Crisis (Field Nulls)
**Company**: Healthcare marketplace
**Context**: March 2020, N95 mask shortage
**Bug**: `mask_type` field was optional in schema

**The Data:**
```json
// 80% of masks indexed like this (correct)
{ "title": "3M N95 Respirator", "mask_type": "N95" }

// 20% indexed like this (missing field)
{ "title": "KN95 Professional Mask" }
// Note: mask_type field completely absent
```

**The Query:**
```json
{ "query": { "term": { "mask_type": "N95" } } }
```

**Result**: 20% of legitimate N95/KN95 masks returned 0 results.
During a pandemic. With life-or-death stakes.

**Fix**:
```python
# Ingestion validator
def validate_mask(doc):
    if "mask" in doc["title"].lower():
        if "mask_type" not in doc or doc["mask_type"] is None:
            raise ValidationError("mask_type required for mask products")
```

---

### Example 3: The "iPhone Case" SEO Spam (Field Contamination)
**Company**: Electronics marketplace
**Bug**: Sellers stuffed keywords into product titles

**Bad Data:**
```json
{
  "title": "iPhone 15 Pro Max Case Cover Samsung Galaxy S24 Pixel 8 Compatible Universal",
  "actual_compatibility": ["iPhone 15 Pro Max"]
}
```

**The Problem:**
- User searches "Samsung Galaxy S24 case"
- Results show iPhone cases (because "Samsung Galaxy S24" is in title)
- User loses trust, leaves site

**Detection Algorithm:**
```python
def detect_title_spam(title, category):
    # Get expected brands for category
    expected_brands = get_category_brands(category)
    
    # Tokenize title
    title_brands = extract_brand_mentions(title)
    
    # If title has > 3 brand mentions, likely spam
    if len(title_brands) > 3:
        return True
    
    # If title mentions brands outside category
    foreign_brands = title_brands - expected_brands
    if len(foreign_brands) > 1:
        return True
    
    return False
```

**Action**: Documents flagged as spam get `quality_score: 0.1` and are demoted in ranking.

---

## 2. The Five Data Quality Failures (Detailed)

### A. Field Contamination
**Definition**: Wrong data in the right field.

**Example: HTML in Description**
```json
// Bad
{
  "description": "<div class=\"product-info\"><p>Great <b>shoes</b>!</p></div>"
}

// After indexing with standard analyzer
Tokens: ["div", "class", "product", "info", "p", "great", "b", "shoes", "b", "p", "div"]

// User searches: "great shoes"
// Also matches: Any product with "div" or "class" in description
```

**Fix**: HTML stripping at ingestion
```python
from bs4 import BeautifulSoup

def clean_html(text):
    soup = BeautifulSoup(text, "html.parser")
    return soup.get_text(separator=" ").strip()
```

---

### B. Schema Drift
**Definition**: Field type changes over time without migration.

**Timeline Example:**
```
2022-01: color = "Red"           (string)
2022-06: color = "RED"           (different case)
2023-01: color = "#FF0000"       (hex code)
2023-06: color = {"name": "Red", "hex": "#FF0000"}  (object!)
```

**Elasticsearch Behavior:**
- First document sets the mapping
- Conflicting types cause indexing failures
- Silent data loss if dynamic mapping is off

**Detection Query:**
```json
GET products/_mapping

// Alert if field type differs from expected
{
  "color": {
    "type": "text"  // Expected: keyword
  }
}
```

---

### C. The Implicit Null Problem
**Definition**: Missing fields treated inconsistently.

**Example: Popularity Ranking**
```python
# The ranking formula
def rank_score(doc):
    relevance = calculate_bm25(query, doc)
    popularity = doc.get("click_count", ???)  # What value for new items?
    return relevance * 0.7 + popularity * 0.3
```

**Options for handling null:**
| Strategy | Value for Null | Effect |
|----------|----------------|--------|
| Zero | 0 | New items buried at bottom |
| Average | 500 | Spam gets free boost |
| Negative | -1 | Explicitly deprioritized |
| Median | 100 | Neutral starting point |

**Best Practice:**
```python
def safe_popularity(doc):
    if "click_count" not in doc or doc["click_count"] is None:
        # Use category median, not global
        return get_category_median_clicks(doc["category"])
    return doc["click_count"]
```

---

### D. Semantic Duplication
**Definition**: Same real-world entity indexed multiple times.

**Example: Multi-Seller Marketplace**
```json
// Seller A
{ "id": "seller-a-iphone15", "title": "Apple iPhone 15 128GB" }

// Seller B  
{ "id": "seller-b-iphone15", "title": "iPhone 15 128 GB (Apple)" }

// Seller C
{ "id": "seller-c-iphone15", "title": "APPLE iPHONE 15 - 128GB" }
```

**User Search**: "iPhone 15"
**Results Page**: Same phone shown 3 times, variety destroyed

**Solution: Entity Resolution Pipeline**
```python
def deduplicate_results(results):
    seen_entities = set()
    unique_results = []
    
    for result in results:
        # Get canonical entity ID
        entity_id = get_entity_id(result)  # "iphone-15-128gb"
        
        if entity_id not in seen_entities:
            seen_entities.add(entity_id)
            unique_results.append(result)
    
    return unique_results
```

---

### E. Join Loss
**Definition**: Related entities become stale/inconsistent.

**Example: Brand Name Change**
```
Day 1: Brand "Facebook" exists with brand_id: 123
Day 2: Brand renamed to "Meta" in Brand table
Day 3: Products still show "Facebook" in search (stale join)
```

**The Fix: Event-Driven Reindexing**
```python
# When brand changes, trigger reindex of all products
@on_event("brand.updated")
def handle_brand_update(brand_id, new_data):
    products = get_products_by_brand(brand_id)
    for product in products:
        # Reindex with fresh brand data
        reindex_product(product.id)
```

---

## 3. Engineering: Building a Data Quality System

### The Quality Score Card
Implement automated gates in your ingestion pipeline.

```python
class DataQualityValidator:
    
    RULES = {
        "title": {
            "required": True,
            "min_length": 10,
            "max_length": 200,
            "no_html": True,
        },
        "price": {
            "required": True,
            "type": "float",
            "min_value": 0.01,
            "max_value": 1000000,
        },
        "image_url": {
            "required": True,
            "must_resolve": True,  # HTTP 200
            "min_dimensions": (100, 100),
        },
    }
    
    def validate(self, doc):
        score = 1.0
        errors = []
        
        for field, rules in self.RULES.items():
            field_score, field_errors = self.validate_field(doc, field, rules)
            score *= field_score
            errors.extend(field_errors)
        
        return {
            "score": score,
            "passed": score >= 0.8,
            "errors": errors
        }
    
    def validate_field(self, doc, field, rules):
        value = doc.get(field)
        
        if rules.get("required") and value is None:
            return 0.0, [f"Missing required field: {field}"]
        
        # ... additional validation logic
        return 1.0, []
```

### Quality Metrics Dashboard

| Metric | Formula | Alert Threshold |
|--------|---------|-----------------|
| **Completeness** | `docs_with_field / total_docs` | < 99.9% |
| **Validity** | `valid_values / non_null_values` | < 99% |
| **Freshness** | `now - last_updated` | > 24 hours |
| **Uniqueness** | `unique_entities / total_docs` | < 95% |
| **Consistency** | `docs_matching_schema / total_docs` | < 99.99% |

### The Quality Score Formula
$$QS(d) = \prod_{i=1}^{n} \left( w_i \cdot C(f_i) \cdot V(f_i) \right)^{1/n}$$

Where:
- $C(f_i)$ = Completeness of field $i$ (1 if present, 0 if null)
- $V(f_i)$ = Validity of field $i$ (1 if valid, 0-1 if partially valid)
- $w_i$ = Business weight of field $i$

**Decision Rule:**
- $QS(d) \geq 0.9$: Index immediately
- $0.7 \leq QS(d) < 0.9$: Index with warning, queue for review
- $QS(d) < 0.7$: **Reject document** - better to not show than show broken
