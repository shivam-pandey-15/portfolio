# Research: 1.4 Types of Search Systems

## Overview
Not all search is the same. Different domains have different requirements.

---

## 1. E-commerce Search

### Examples
Amazon, Flipkart, Shopify, Etsy, Walmart, Alibaba

### Characteristics
- **Structured data**: Products have attributes (price, brand, size, color)
- **Business logic heavy**: In-stock items first, margin considerations
- **Faceted navigation**: Filter by price range, brand, ratings
- **Merchandising**: Promoted products, seasonal boosts
- **Personalization**: Based on purchase history, browsing

### Real-World Problems Solved

**Problem 1: Variant Explosion**
- Query: "Nike Air Max"
- Challenge: Same shoe in 20 sizes, 5 colors = 100 variants
- Bad UX: 100 identical-looking results
- Solution: Collapse by parent SKU, show "20 sizes available"

**Problem 2: The "Cheap" Problem**
- Query: "cheap laptop"
- Bad result: $2,000 MacBook (because it's popular)
- Why: Popularity signal overwhelms price intent
- Solution: Detect price intent, boost low-price items

**Problem 3: Inventory Sync**
- Query: "PlayStation 5"
- Bad result: Out-of-stock item at position 1
- Why: Indexing happens hourly, sold out 5 minutes ago
- Solution: Real-time inventory signal, or demote after threshold

**Problem 4: Seller Spam (Marketplaces)**
- Query: "iPhone case"
- Bad result: 50 identical products from different sellers
- Why: Each seller creates their own listing
- Solution: Duplicate detection, buy box logic

### Key Metrics
- Conversion rate from search
- Add-to-cart rate
- Revenue per search
- Return rate from search

---

## 2. Document / Enterprise Search

### Examples
Notion, Confluence, SharePoint, Google Drive, Elastic Enterprise Search

### Characteristics
- **Unstructured text**: Documents, wikis, PDFs, emails
- **Access control**: User can only see documents they have permission for
- **Recency matters**: Latest version of a document
- **Entity extraction**: People, dates, project names
- **No "conversion"**: Success = finding the right document

### Real-World Problems Solved

**Problem 1: Permission Explosion**
- Scenario: 10M documents, user has access to 1K
- Bad approach: Retrieve 1000 docs, filter in app layer (slow)
- Good approach: Filter at index level with security bits
- Example: SharePoint indexes ACLs directly in the search index

**Problem 2: Version Confusion**
- Query: "Q3 budget proposal"
- Bad result: 5 versions of the same doc from 5 people
- Why: Each edit creates a new version
- Solution: Collapse by document ID, show "last modified by..."

**Problem 3: Content Extraction**
- Query: "Project Alpha timeline"
- Bad result: No results
- Why: Info is in a PowerPoint slide, not indexed
- Solution: OCR + content extraction for PDFs, PPTs, images

**Problem 4: No Click Signal**
- Challenge: How do you know if search is good?
- E-commerce has purchases. Documents don't.
- Solution: Explicit feedback ("Was this helpful?"), dwell time

### Key Metrics
- Time to find document
- Search success rate (did user find what they needed?)
- Query abandonment
- Feedback ratings

---

## 3. Web Search

### Examples
Google, Bing, DuckDuckGo, Brave Search, Yandex

### Characteristics
- **Massive scale**: Billions of pages
- **Crawling required**: Content must be discovered and indexed
- **Link analysis**: PageRank, authority signals
- **Spam detection**: SEO manipulation
- **Intent diversity**: Navigational, informational, transactional

### Real-World Problems Solved

**Problem 1: The Freshness vs Authority Trade-off**
- Query: "World Cup score"
- Bad result: Wikipedia article about World Cup (authoritative but stale)
- Good result: Live score from news site (fresh but less authoritative)
- Solution: Query intent detection (this is temporal → boost fresh)

**Problem 2: Spam at Scale**
- Challenge: 1000 new spam pages created per minute
- Tactics: Link farms, keyword stuffing, hidden text
- Solution: ML-based spam detection, link graph analysis

**Problem 3: Local Intent**
- Query: "pizza near me"
- Bad result: Famous NYC pizza place (user is in LA)
- Solution: Geo-signals (IP, device location, query patterns)

**Problem 4: Zero-Click Cannibalization**
- Query: "What is the capital of France?"
- User sees "Paris" in featured snippet, never clicks
- Problem: Publisher gets no traffic
- Solution: Google's ongoing ethical/business debate

**Problem 5: Personalization Without Filter Bubbles**
- Query: "climate change"
- Risk: Only showing user what they already believe
- Solution: Diversity in results, transparent personalization

### Key Metrics
- Query success rate
- Time to satisfaction
- Click-through rate
- Pogo-sticking rate

---

## 4. Code Search

### Examples
GitHub, Sourcegraph, Grep.app, OpenGrok, Google Code Search

### Characteristics
- **Syntax-aware**: Understand code structure (functions, classes)
- **Regex/pattern support**: Developers expect regex
- **Exact match important**: "getUser" ≠ "get_user"
- **Large files**: Single file can be 10K+ lines
- **Cross-repository**: Search across thousands of repos

### Real-World Problems Solved

**Problem 1: Naming Convention Chaos**
- Query: "get user by id"
- Codebase has: `getUserById`, `get_user_by_id`, `GetUserByID`, `getUser`
- Solution: Camel case splitting, normalization

**Problem 2: Symbol vs Text Search**
- Query: "getUser"
- User wants: Function definition and all usages
- Bad result: 1000 matches including comments and strings
- Solution: AST-aware search, distinguish definitions from references

**Problem 3: Monorepo Scale**
- Google's monorepo: 2+ billion lines of code
- Challenge: Can't do full regex scan in real-time
- Solution: Trigram indices, pre-computed indexes, smart pruning

**Problem 4: Multi-Language**
- Query: "authentication handler"
- Codebase has: Python, Java, Go, TypeScript
- Challenge: Different syntax patterns per language
- Solution: Language-aware tokenizers, unified schema

**Problem 5: Security (Secrets Search)**
- Bad: Accidentally indexed AWS keys, passwords
- Solution: Secret scanning, gitignore-like exclusion rules

### Key Metrics
- Time to find code
- Navigation success (did user find the right file?)
- Symbol resolution accuracy
- False positive rate

---

## 5. Log / Observability Search

### Examples
Splunk, Elasticsearch (ELK), Datadog, Grafana Loki, Honeycomb

### Characteristics
- **Time-series**: Logs have timestamps, queries are time-bounded
- **High volume**: Millions of events per second
- **Exact match**: Error codes, IDs, stack traces
- **Aggregations**: Count errors per minute, group by host
- **Retention policies**: Old logs are deleted

### Real-World Problems Solved

**Problem 1: Ingestion During Incidents**
- Scenario: Service is crashing, emitting 10x normal log volume
- Bad: Ingestion pipeline can't keep up, logs are delayed/dropped
- Solution: Backpressure handling, priority queues for error-level

**Problem 2: Cost of Full-Text**
- Challenge: 1 PB of logs, user wants to search for "user_id=12345"
- Bad approach: Full scan (hours, $$$)
- Solution: Columnar storage, bloom filters, indexed fields

**Problem 3: Hot/Cold Storage**
- Last 24 hours: Need sub-second queries
- Last 30 days: Acceptable to wait 10 seconds
- Older: Archive to S3, query if needed
- Solution: Tiered storage with automatic rollover

**Problem 4: Structured vs Unstructured**
- Some logs: `{"level": "error", "user_id": 123}`
- Other logs: `[ERROR] User 123 failed to login`
- Challenge: Unified search across both
- Solution: Schema-on-read, dynamic field extraction

### Key Metrics
- Query latency (P50, P99)
- Ingestion lag
- Cost per GB searched
- Data completeness during incidents

---

## 6. Media Search

### Examples
YouTube, Spotify, Netflix, Pinterest, TikTok, Instagram

### Characteristics
- **Multimodal**: Text, image, audio, video
- **Content understanding**: What's IN the video/image
- **Personalization heavy**: Same query, different results per user
- **Engagement focus**: Optimize for watch time, not just clicks
- **Recommendation overlap**: Search and recs are tightly coupled

### Real-World Problems Solved

**Problem 1: Content Understanding**
- Query: "funny cat videos"
- Challenge: Title might be "My pet doing silly things"
- Solution: Video frame analysis, audio transcription, ML tags

**Problem 2: The Long Tail**
- 99% of YouTube videos are never searched directly
- Challenge: How do you surface niche content?
- Solution: Recommendations, "similar videos", creator promotion

**Problem 3: Personalization at Scale**
- Query: "workout"
- User A: Wants yoga
- User B: Wants heavy lifting
- Solution: User embedding + content embedding → personalized ranking

**Problem 4: Audio Search (Spotify/Shazam)**
- Query: "That song that goes da da da da"
- Challenge: No text to match
- Solution: Audio fingerprinting, melody matching, lyrics search

**Problem 5: Thumbnail Optimization**
- Same video, different thumbnails per user
- Challenge: Which thumbnail gets clicks?
- Solution: Multi-armed bandit testing, user preference models

**Problem 6: Creator SEO Abuse**
- Title: "INSANE TRICK!! You won't BELIEVE... (NOT CLICKBAIT)"
- Challenge: Spammy titles game the algorithm
- Solution: Engagement quality signals (watch time, not just clicks)

### Key Metrics
- Watch time from search
- Discovery rate (found something new)
- Engagement depth
- Creator satisfaction (content is surfaced fairly)

---

## Comparison Matrix

| Type | Data Structure | Personalization | Latency SLA | Key Challenge | Scale Example |
|------|----------------|-----------------|-------------|---------------|---------------|
| E-commerce | Structured | Medium | P99 < 100ms | Business logic | 500M products (Amazon) |
| Document | Unstructured | Low | P99 < 500ms | Permissions | 2B docs (Google Drive) |
| Web | Massive/Crawled | High | P99 < 200ms | Spam | 130T pages (Google) |
| Code | Syntax-aware | Low | P99 < 500ms | Tokenization | 200M repos (GitHub) |
| Log | Time-series | None | P99 < 1s | Volume | 1PB/day (Netflix) |
| Media | Multimodal | Very High | P99 < 200ms | Content understanding | 800M videos (YouTube) |

---

## When to Use Which Technology

| Your Use Case | Start With | Upgrade To |
|---------------|------------|------------|
| Simple product catalog | Algolia, Typesense | Elasticsearch |
| Document search < 1M docs | Meilisearch | Elasticsearch |
| Document search > 10M docs | Elasticsearch | Vespa, custom |
| Log search | Loki (if Kubernetes) | Elasticsearch, Splunk |
| Code search | grep + basic indexing | Sourcegraph, Zoekt |
| Media/ML-heavy | Vespa, Weaviate | Custom vector DB |

---

## Key Takeaways

1. **Different domains have different constraints**
2. **E-commerce is business-logic heavy; Web search is spam-heavy**
3. **Document search requires access control; Log search requires volume**
4. **Code search needs syntax awareness; Media search needs ML**
5. **The core IR principles apply to all**, but implementation varies significantly
6. **Start simple, upgrade when you hit specific pain points**
