# 3.5 Segments & Immutability

## Plain English Summary

**Imagine a search engine as a library where you can NEVER erase or change ink once it's written.**

When you add a book to this library, it gets written on fresh paper and sealed. If you want to update it, you write a NEW version on new paper, and the old one gets marked as "outdated". Eventually, a librarian comes around to copy all the valid books into new, organized volumes, and throws away the outdated ones.

This is how Lucene (the engine behind Elasticsearch) works. Data is written to **segments** - immutable files that are never modified. Updates create new segments. Deletes just mark documents as "deleted" but don't remove them. Background processes merge segments and reclaim space.

**Why this design?** It enables incredibly fast reads without locking and makes crashes recoverable.

---

## Real-World Analogy: The Append-Only Ledger

Think of a financial ledger where you can only ADD entries, never modify them:

**Traditional approach (mutable):**
```
Entry 1: John paid $100 â† $50  (Crossed out and changed)
Entry 2: Jane paid $200

Problem: If we crash during the cross-out, data is corrupted!
```

**Append-only approach (immutable):**
```
Entry 1: John paid $100
Entry 2: Jane paid $200
Entry 3: Correction: John's entry is now $50 (Entry 1 superseded)

Benefits:
- Never risk corrupting existing data
- Full audit trail
- Can recover from any crash point
```

Segments work the same way. Once written, they're sealed forever.

---

## The Segment Lifecycle (Complete Journey)

Let's trace the complete lifecycle of data in a search engine:

### Stage 1: Data Arrives

```
You send: POST /products/_doc
{
  "title": "MacBook Pro",
  "price": 2499
}
```

### Stage 2: In-Memory Buffer (Not Yet Durable or Searchable)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          IN-MEMORY BUFFER            â”‚
â”‚                                      â”‚
â”‚  Doc 1: MacBook Pro, $2499           â”‚
â”‚  Doc 2: ThinkPad, $1299              â”‚
â”‚  Doc 3: Surface Pro, $1599           â”‚
â”‚                                      â”‚
â”‚  STATUS: Fast to add (RAM)           â”‚
â”‚          NOT searchable yet          â”‚
â”‚          Would be lost on crash      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stage 3: Translog (Durable, But Not Searchable)

Simultaneously, data is appended to the **translog** (transaction log):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            TRANSLOG (Disk)           â”‚
â”‚                                      â”‚
â”‚  [Doc 1: MacBook Pro, $2499]         â”‚
â”‚  [Doc 2: ThinkPad, $1299]            â”‚
â”‚  [Doc 3: Surface Pro, $1599]         â”‚
â”‚                                      â”‚
â”‚  STATUS: On disk (survives crash)    â”‚
â”‚          Used for recovery           â”‚
â”‚          Append-only (very fast)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**At this point:**
- âœ… Data is SAFE (won't be lost if we crash)
- âŒ Data is NOT SEARCHABLE (not in any segment yet)

### Stage 4: Refresh (Durable AND Searchable)

Every 1 second (default), a **refresh** occurs:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          REFRESH OPERATION           â”‚
â”‚                                      â”‚
â”‚  In-Memory Buffer  â†’  New Segment    â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Doc 1      â”‚     â”‚ Segment 0  â”‚  â”‚
â”‚  â”‚ Doc 2      â”‚ â”€â”€â–º â”‚            â”‚  â”‚
â”‚  â”‚ Doc 3      â”‚     â”‚ Immutable! â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   (Buffer emptied)   (Now on disk)  â”‚
â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**After refresh:**
- âœ… Data is SEARCHABLE (queries can find it)
- âœ… Data is DURABLE (written to segment file)
- âŒ But now we have many tiny segments...

### Stage 5: Merge (Optimization)

Over time, you accumulate many segments:

```
Before Merge:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Seg 0  â”‚ â”‚ Seg 1  â”‚ â”‚ Seg 2  â”‚ â”‚ Seg 3  â”‚ â”‚ Seg 4  â”‚
â”‚ 10 MB  â”‚ â”‚ 8 MB   â”‚ â”‚ 12 MB  â”‚ â”‚ 5 MB   â”‚ â”‚ 3 MB   â”‚
â”‚ 1000   â”‚ â”‚ 800    â”‚ â”‚ 1200   â”‚ â”‚ 500    â”‚ â”‚ 300    â”‚
â”‚ docs   â”‚ â”‚ docs   â”‚ â”‚ docs   â”‚ â”‚ docs   â”‚ â”‚ docs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Problem: Query must check ALL 5 segments!

After Merge (background process):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Segment A                    â”‚
â”‚                 38 MB                        â”‚
â”‚                 3800 docs                    â”‚
â”‚                                             â”‚
â”‚     (Old segments deleted)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefit: Query checks only 1 segment!
```

### Stage 6: Flush (Full Durability)

Periodically, a **flush** commits everything:

```
FLUSH:
1. All segments are fsync'd to disk (guaranteed durable)
2. Translog is cleared (no longer needed for recovery)
3. A "commit point" is recorded
```

**When flush happens:**
- Every 30 minutes (default)
- When translog exceeds 512MB
- Manual trigger: `POST /index/_flush`

---

## Why Immutability Matters

### Benefit 1: No Locking Required

**Mutable approach (databases):**
```
Thread 1: Reading row 100
Thread 2: Wants to update row 100
Thread 2: BLOCKED! Waiting for Thread 1 to finish...
          â†’ Lock contention, performance degradation
```

**Immutable approach (Lucene):**
```
Thread 1: Reading Segment 5
Thread 2: Creating Segment 6 (with updated data)
Thread 1: Still reading Segment 5 (not affected!)
          â†’ No locking, parallel execution
```

### Benefit 2: Excellent Caching

```
Operating System Page Cache:

Mutable file:
  - Content might change any moment
  - Cache could become stale
  - Must check for modifications
  
Immutable segment:
  - Content NEVER changes
  - Cache is always valid
  - OS keeps hot segments in RAM automatically
  
Result: "Warm" queries are 10x faster than "cold" queries
```

### Benefit 3: Instant Snapshots

```
Snapshot = List of segment file names

Since segments never change:
- No need to copy any data
- Just record which segments exist
- Point-in-time backup in milliseconds!

// Create snapshot
PUT /_snapshot/my_backup/snapshot_1
{
  "indices": "products"
}

Time: ~100ms for a 100GB index!
```

### Benefit 4: Crash Recovery

```
Crash at any point:
1. Read last "commit point" 
2. Replay translog from that point
3. Fully recovered!

No fsck, no corruption repairs, no data loss.
```

---

## The Delete Problem (Tombstones)

### How Deletes Work

Since segments are immutable, we can't actually remove data:

```
You send: DELETE /products/_doc/123

What happens:
1. Find segment containing doc 123 (let's say Segment 2)
2. Segment 2 is immutable - can't modify it!
3. Instead, update the ".liv" (live docs) file:
   
   .liv file for Segment 2:
   [1, 1, 1, 0, 1, 1, ...]
            â†‘
            Doc 123 marked as "not live"
4. Original document bytes STILL EXIST in segment!
```

### The Tombstone Tax

Deleted documents still consume resources:

**Storage:**
```
Index: 100GB
Deleted docs: 20%
Actual useful data: 80GB
Wasted space: 20GB (until merge!)
```

**Query performance:**
```
For each segment:
    matches = search(query)
    
    for doc in matches:
        if not live_docs[doc]:  // Extra check!
            skip
        else:
            add_to_results

With 0% deleted: 10ms
With 20% deleted: 12ms (+20%)
With 50% deleted: 18ms (+80%)
```

### When Tombstones Get Cleaned Up

Deleted documents are permanently removed during **segment merge**:

```
Before merge:
  Segment A: docs [1, 2, 3, 4, 5], deleted: [2, 4]
  Segment B: docs [6, 7, 8], deleted: [7]

After merge:
  Segment AB: docs [1, 3, 5, 6, 8]
  
  Docs 2, 4, 7 are GONE - storage reclaimed!
```

---

## The Segment Explosion Problem

### What Causes It

```
Refresh interval: 1 second
Segments created per day: 86,400

If merges can't keep up:
  Day 1: 86,400 tiny segments
  Day 2: 172,800 segments
  Day 3: Cluster on fire ğŸ”¥
```

### Symptoms

1. **Query slowdown**: Must check thousands of segments
2. **File handle exhaustion**: Linux default ulimit ~65,000
3. **Memory pressure**: Each segment has metadata in heap
4. **Merge storms**: Catch-up merging consumes all I/O

### Diagnosing

```json
GET /_cat/segments/products?v&h=index,shard,segment,docs.count,size

// Healthy:
index    shard segment docs.count size
products 0     _0      1000000    500mb
products 0     _1      500000     250mb
products 0     _2      100000     50mb

// Unhealthy (explosion!):
index    shard segment docs.count size
products 0     _0      100        50kb
products 0     _1      100        50kb
products 0     _2      100        50kb
... (500 more tiny segments)
```

### Solutions

**1. Increase refresh interval:**
```json
PUT /products/_settings
{
  "index.refresh_interval": "30s"  // Instead of 1s
}

30x fewer segments created!
```

**2. Disable during bulk load:**
```json
// Before bulk loading
PUT /products/_settings
{
  "index.refresh_interval": "-1",
  "index.number_of_replicas": 0
}

// Load millions of documents...

// After bulk loading
POST /products/_refresh
PUT /products/_settings
{
  "index.refresh_interval": "1s",
  "index.number_of_replicas": 1
}
```

**3. Force merge (use carefully!):**
```json
POST /products/_forcemerge?max_num_segments=1

// âš ï¸ WARNING:
// - Blocks writes during merge
// - Creates HUGE segment that won't auto-merge
// - ONLY use for read-only (time-series) indices
```

---

## Merge Policy Deep Dive

### Tiered Merge Policy (Default)

```
Goal: Keep segments of similar size together

Configuration:
  segments_per_tier: 10
  max_merge_at_once: 10
  max_merged_segment: 5GB

How it works:
  Level 0 (tiny):    [5MB] [5MB] [5MB] [5MB] [5MB] [5MB] [5MB] [5MB] [5MB] [5MB]
                                    â†“ merge (10 segments)
  Level 1 (small):   [50MB] [5MB] [5MB] [5MB] [5MB] [5MB]
                            â†“ wait for more tiny segments
                            â†“ another merge
  Level 1 (small):   [50MB] [50MB] [5MB] [5MB]
                            â†“ merge
  Level 2 (medium):  [100MB] [10MB] [10MB]
                            â†“ continue...
  Level 3 (large):   [500MB]
```

### Tuning Merge Policy

```json
PUT /products/_settings
{
  "index.merge.policy.segments_per_tier": 10,
  "index.merge.policy.max_merge_at_once": 10,
  "index.merge.policy.max_merged_segment": "5gb",
  "index.merge.scheduler.max_thread_count": 1  // Reduce I/O pressure
}
```

---

## Write Amplification

### The Hidden Cost of Immutability

```
You think: Write 1 document = 1 write operation

Reality:
  1. Write to translog (fsync)
  2. Write to in-memory buffer
  3. Refresh â†’ write new segment
  4. Merge level 1 â†’ rewrite into larger segment
  5. Merge level 2 â†’ rewrite again
  6. Merge level 3 â†’ rewrite again

1 document might be written to disk 5-7 times!
```

### Planning for Write Amplification

```
Ingestion rate: 10,000 docs/sec
Average doc size: 1 KB

Logical writes: 10 MB/sec
Actual disk I/O: 50-70 MB/sec (5-7x amplification)

When sizing disks:
- Plan for 7x write amplification
- Use SSDs (random I/O is brutal on HDDs)
- Leave 50% disk headroom for merges
```

---

## Key Takeaways

1. **Segments are immutable** - once written, never modified. This enables lock-free reads and safe recovery.

2. **New data â†’ new segments**. Refresh interval controls latency vs segment count.

3. **Deletes create tombstones**, not actual deletions. Merging reclaims space.

4. **Watch for segment explosion** during high-throughput ingestion.

5. **Write amplification is 5-7x** - plan disk capacity accordingly.

6. **Force merge is dangerous** - only use for read-only indices.

---

## Forward References

- **[Ch 4.6 Freshness](../data-foundation/4.6-freshness.md)**: Tuning refresh interval for your use case
- **[Ch 4.7 Deletes](../data-foundation/4.7-deletes.md)**: Strategies for handling high-delete workloads
