# 3.1 What is an Index?

## Plain English Summary

**Think of an index like the back of a textbook.**

When you want to find every page that mentions "photosynthesis", you don't read the entire book page by page. You go to the index at the back, look up "photosynthesis", and it tells you: "pages 45, 78, 112". 

A search engine index works the same way, but for millions of documents and billions of words. Instead of page numbers, it stores document IDs. Instead of scanning every document for your search term, it instantly looks up which documents contain that term.

**The trade-off:** Creating this index takes time and space upfront (like someone had to read the whole book to create the index). But once it exists, finding things is almost instant.

---

## Real-World Analogy: The Library Card Catalog

Imagine a library with 1 million books. How do you find books about "machine learning"?

**Without an Index (The Database Approach):**
- Walk to shelf 1, check book 1. Does it mention "machine learning"? No.
- Walk to shelf 1, check book 2. Does it mention "machine learning"? No.
- Continue for 1 million books...
- **Time: Several years of your life.**

**With an Index (The Search Engine Approach):**
- Go to the card catalog (the index)
- Look up "machine learning"
- Find: "Books 4521, 8903, 15234, 99012..."
- Walk directly to those shelves
- **Time: 5 minutes.**

The index contains:
- **Every unique word** in every book (the "vocabulary")
- **Which books contain each word** (the "posting lists")

---

## The Fundamental Trade-off

Every search system makes this trade-off:

| Aspect | Database (No Index) | Search Engine (Indexed) |
|--------|---------------------|-------------------------|
| **Write Speed** | Fast (just append) | Slow (must analyze & index) |
| **Read Speed (by ID)** | Fast | Fast |
| **Read Speed (text search)** | **Slow (scan all)** | **Fast (index lookup)** |
| **Storage** | 1x (just the data) | 3-5x (data + index structures) |
| **Consistency** | Immediate | Eventually consistent |

**The First Law of Search:**
> We pay upfront with slower writes and more storage to get faster reads.

---

## What Happens When You Index a Document

Let's trace what happens when you add a product to a search engine:

### Step 1: You Send the Document

```json
POST /products/_doc
{
  "title": "Apple MacBook Pro 16-inch M3 Max",
  "price": 2499.99,
  "category": "laptops"
}
```

### Step 2: The Engine Breaks Down the Text

The `title` field goes through **analysis**:

```
Input:  "Apple MacBook Pro 16-inch M3 Max"
         ↓
Tokenizer (split on spaces and punctuation):
         ["Apple", "MacBook", "Pro", "16", "inch", "M3", "Max"]
         ↓
Lowercase filter:
         ["apple", "macbook", "pro", "16", "inch", "m3", "max"]
         ↓
These become the "terms" that go into the index.
```

### Step 3: The Engine Updates Multiple Data Structures

**A. Inverted Index (for text search):**
```
"apple"    → [doc_1]
"macbook"  → [doc_1]
"pro"      → [doc_1]
"16"       → [doc_1]
"inch"     → [doc_1]
"m3"       → [doc_1]
"max"      → [doc_1]
```

**B. BKD Tree (for numeric range queries):**
```
price: 2499.99 → doc_1
```

**C. Keyword Index (for exact matches and filtering):**
```
category: "laptops" → doc_1
```

**D. Stored Fields (for returning the original document):**
```
doc_1 → {"title": "Apple MacBook Pro...", "price": 2499.99, "category": "laptops"}
```

### Step 4: Write Amplification

For this one document, the engine performed approximately:
- 7 term dictionary lookups/inserts
- 7 posting list updates
- 1 BKD tree insert
- 1 keyword index insert
- 1 stored field write
- 1 translog append (for durability)

**One document → ~20 internal operations**

This is called **write amplification**. It's the price we pay for fast reads.

---

## The Index Hierarchy: Zooming Out

A search index is not a single file. It's a hierarchy:

```
┌─────────────────────────────────────────────────────────────┐
│                         CLUSTER                             │
│                    (Group of Nodes)                         │
│                                                             │
│   Node 1 (Machine)    Node 2 (Machine)    Node 3 (Machine) │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                         INDEX                               │
│                   (Logical Namespace)                        │
│                    "products"                               │
│                                                             │
│  This is what your application sees. A single index name.  │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                         SHARDS                              │
│                  (Physical Partitions)                       │
│                                                             │
│   ┌─────────┐   ┌─────────┐   ┌─────────┐                  │
│   │ Shard 0 │   │ Shard 1 │   │ Shard 2 │                  │
│   │(Primary)│   │(Primary)│   │(Primary)│                  │
│   └─────────┘   └─────────┘   └─────────┘                  │
│                                                             │
│   Each shard can live on a different machine.              │
│   Documents are distributed by: hash(doc_id) % num_shards  │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                        REPLICAS                             │
│                    (Backup Copies)                          │
│                                                             │
│   ┌─────────┐   ┌─────────┐   ┌─────────┐                  │
│   │ Shard 0 │   │ Shard 1 │   │ Shard 2 │                  │
│   │(Replica)│   │(Replica)│   │(Replica)│                  │
│   └─────────┘   └─────────┘   └─────────┘                  │
│                                                             │
│   Replicas are kept on different nodes for fault tolerance.│
│   They also serve read requests (distributing load).       │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                        SEGMENTS                             │
│                   (Immutable Files)                          │
│                                                             │
│   Each shard is made up of multiple segments:              │
│                                                             │
│   ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐                      │
│   │ Seg0 │ │ Seg1 │ │ Seg2 │ │ Seg3 │                      │
│   │100MB │ │ 50MB │ │ 10MB │ │ 5MB  │                      │
│   └──────┘ └──────┘ └──────┘ └──────┘                      │
│                                                             │
│   New data creates new segments. Old segments are merged.  │
│   Segments are NEVER modified once written.                │
└─────────────────────────────────────────────────────────────┘
```

### Why This Hierarchy Matters

| Level | Purpose | Can Change After Creation? |
|-------|---------|---------------------------|
| **Index** | Naming, settings | Some settings yes, name no |
| **Shards** | Horizontal scaling | **NO** - shard count is fixed! |
| **Replicas** | Availability, read throughput | Yes, anytime |
| **Segments** | Immutable storage units | N/A (managed automatically) |

---

## Deep Dive: Index vs Database

### Why Not Just Use a Database?

Databases are optimized for different access patterns:

**PostgreSQL (B-Tree Index):**
```sql
-- Fast (uses index):
SELECT * FROM products WHERE id = 123;

-- Slow (full table scan):
SELECT * FROM products WHERE description LIKE '%lightweight laptop%';
```

The `LIKE '%...'` query cannot use an index because B-Trees work left-to-right. You can only efficiently find strings that *start with* a prefix, not strings that *contain* a substring.

**Elasticsearch (Inverted Index):**
```json
// Fast (uses inverted index):
{
  "query": {
    "match": {
      "description": "lightweight laptop"
    }
  }
}
```

Every word in every document is indexed. Finding documents containing "lightweight" is a single lookup.

### The Numbers

| Operation | PostgreSQL | Elasticsearch |
|-----------|------------|---------------|
| Exact ID lookup | 0.5ms | 0.5ms |
| Text search (10M docs) | 5000ms | 5ms |
| Phrase search | 10000ms | 10ms |
| Faceted aggregation | 2000ms | 50ms |

**1000x difference for text search.**

---

## Practical: Creating an Index

### Elasticsearch Example

```json
PUT /products
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "refresh_interval": "1s"
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "english"
      },
      "price": {
        "type": "float"
      },
      "category": {
        "type": "keyword"
      },
      "created_at": {
        "type": "date"
      }
    }
  }
}
```

**Breaking this down:**

| Setting | What it does | When to change |
|---------|--------------|----------------|
| `number_of_shards: 3` | Split data into 3 partitions | Based on data size (20-50GB per shard ideal) |
| `number_of_replicas: 1` | Keep 1 backup copy per shard | 0 for dev, 1+ for production |
| `refresh_interval: 1s` | New docs searchable in 1 second | Increase for bulk loading |
| `type: text` | Full-text searchable | For natural language content |
| `type: keyword` | Exact matches only | For IDs, categories, tags |
| `type: float` | Range queries | For prices, ratings |

---

## Real-World Sizing Guide

### Startup Scale
```
Products: 100,000
Raw Data: 200MB
Index Size: ~600MB (3x raw)
Shards: 1 (no need to split)
Nodes: 1 (laptop is fine)
```

### E-commerce Scale
```
Products: 10 million
Raw Data: 20GB
Index Size: ~60GB
Shards: 2-3 primary
Nodes: 3 (for availability)
```

### Marketplace Scale
```
Products: 500 million
Raw Data: 1TB
Index Size: ~3TB
Shards: 60-100 primary
Nodes: 15-20 (multi-region)
```

### The Sizing Formula

```
Ideal Shards = Total Index Size ÷ 30GB

Example:
- Index Size: 150GB
- Ideal Shards: 150 ÷ 30 = 5 shards
```

---

## Key Takeaways

1. **An index is a read-optimized data structure** that trades write speed and storage for fast reads.

2. **Write amplification is real**: 1 document = ~20 internal operations.

3. **The hierarchy matters**: Index → Shards → Replicas → Segments. Shard count is fixed at creation!

4. **Use search engines for text, databases for transactions**: Each tool excels at different things.

5. **Size your shards**: Target 20-50GB per shard for optimal performance.

---

## Forward References

- **[3.5 Segments](3.5-segments.md)**: Why segments are immutable and how merging works.
- **[3.6 Sharding](3.6-sharding.md)**: How documents are distributed and queries are coordinated.
