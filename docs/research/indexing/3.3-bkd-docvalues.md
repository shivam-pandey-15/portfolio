# 3.3 BKD Trees & DocValues (Structured Data)

## Plain English Summary

**The inverted index is great for text, but terrible for numbers.**

If you want to find all products between $100 and $200, an inverted index would have to look up every possible price: "100", "100.01", "100.02", ... "199.99", "200". That's 10,000+ lookups!

Instead, search engines use **BKD Trees** for numeric data. Think of it like a smart filing system that organizes numbers spatially, so you can quickly find all numbers in a range.

**DocValues** are a companion structure that lets you quickly get the *value* for a *document*. While the inverted index answers "which documents have term X?", DocValues answer "what's the value of field Y for document Z?" — essential for sorting and aggregations.

---

## Real-World Analogy: The Library File Cabinet

Imagine organizing books by their publication year:

**Inverted Index Approach (Bad for Numbers):**
```
Year 2020: [Book 5, Book 23, Book 89]
Year 2021: [Book 12, Book 34]
Year 2022: [Book 1, Book 67, Book 78]
Year 2023: [Book 45, Book 90]
...

Query: "Books published 2020-2023"
→ Look up 2020, 2021, 2022, 2023 separately
→ Merge all results
→ Gets worse as range grows!
```

**BKD Tree Approach (Good for Numbers):**
```
Organize books spatially by year:

     ┌─────────────┐
     │  All Books  │
     └──────┬──────┘
            │
  ┌─────────┴─────────┐
  │                   │
Years 2000-2012    Years 2013-2025
  │                   │
  ...         ┌───────┴───────┐
              │               │
          2013-2019       2020-2025 ← Query target!
                              │
                       Just scan this branch

Query: "Books published 2020-2023"
→ Navigate to 2020-2025 branch
→ Scan only matching books
→ O(log N) to find the branch!
```

---

## BKD Trees: How They Work

### The Basic Idea

A BKD tree (Block K-D Tree) organizes multi-dimensional points by recursively splitting space.

**For 1D data (like price):**
```
Products with prices: $50, $100, $150, $200, $250, $300, $350, $400

                    ┌───────────────────┐
                    │    All Products   │
                    │   $50 - $400      │
                    └─────────┬─────────┘
                              │
               ┌──────────────┴──────────────┐
               │                             │
        ┌──────┴──────┐               ┌──────┴──────┐
        │  $50-$200   │               │ $250-$400   │
        └──────┬──────┘               └──────┬──────┘
               │                             │
       ┌───────┴───────┐             ┌───────┴───────┐
       │               │             │               │
   [$50,$100]    [$150,$200]    [$250,$300]    [$350,$400]
```

**Query: price BETWEEN $100 AND $300**
1. Start at root
2. Left subtree ($50-$200) overlaps with query → follow
3. Right subtree ($250-$400) overlaps with query → follow
4. In leaves, scan only matching values

**Complexity: O(log N) to find branches + O(matches) to scan**

### For 2D Data (like lat/lon):

```
Points on a map:

         ┌─────────────────────────────────┐
         │                                 │
         │    A          B                 │
         │   ●          ●                  │
         │                                 │
         ├─────────────────────────────────┤ (Split horizontally)
         │                                 │
         │         C ●                     │
         │                    D ●          │
         │                                 │
         └─────────────────────────────────┘

After splitting:
            ┌───────────────┐
            │   All Points  │
            └───────┬───────┘
                    │
         ┌──────────┴──────────┐
         │                     │
     Top Half              Bottom Half
     (A, B)                (C, D)
         │                     │
    Further splits...     Further splits...
```

This is how Elasticsearch does **geo queries**: it finds the relevant geographic area by navigating the tree.

---

## BKD vs Inverted Index: The Numbers

**Dataset: 100 million products with price field**

| Query | Inverted Index | BKD Tree |
|-------|----------------|----------|
| `price = 100` | 5ms | 2ms |
| `price > 100` | 5000ms (!) | 10ms |
| `price BETWEEN 100 AND 200` | 500ms | 5ms |
| `price BETWEEN 100 AND 100000` | Timeout | 15ms |

**Why the massive difference?**

For `price > 100`:
- **Inverted Index**: Must look up every term > 100 separately. With prices from $1-$10000 at $0.01 increments, that's 990,000 term lookups!
- **BKD Tree**: Navigate tree once, scan matching leaves. Maybe 10 node visits total.

### Storage Efficiency

```
100 million 32-bit integers:

Uncompressed: 100M × 4 bytes = 400 MB

BKD Tree (with compression):
- Delta encoding within blocks
- Bit-packing for small values
- Block size: 512-1024 values

Compressed: ~50 MB (8x compression!)
```

---

## DocValues: The Column Store

### Why We Need DocValues

The inverted index tells us WHICH documents match. But for sorting and aggregations, we need to know the VALUE for each document.

**Without DocValues:**
```
Query: Search "laptop", sort by price

Step 1: Find matching docs via inverted index
        "laptop" → [doc1, doc5, doc23, doc100, ...]

Step 2: Get price for each doc... how?

Option A: Stored Fields (_source)
        doc1 → {"title": "...", "price": 999, "description": "...500 more chars..."}
        
        Problem: Must parse entire JSON, extract price
        For 10,000 results: Parse 10,000 JSON documents!
        Time: 500ms
```

**With DocValues:**
```
Query: Search "laptop", sort by price

Step 1: Find matching docs via inverted index
        "laptop" → [doc1, doc5, doc23, doc100, ...]

Step 2: Look up prices in DocValues
        prices: [doc1→999, doc5→1299, doc23→799, doc100→1599, ...]
        
        Just array access! No parsing!
        For 10,000 results: 10,000 array lookups
        Time: 5ms
```

### How DocValues Are Stored (Columnar Layout)

**Row-oriented (_source / stored fields):**
```
doc1: {"title": "MacBook", "price": 2499, "stock": 50, "rating": 4.8}
doc2: {"title": "ThinkPad", "price": 1299, "stock": 120, "rating": 4.5}
doc3: {"title": "Surface", "price": 1899, "stock": 30, "rating": 4.6}
```

To get all prices: Read 3 full documents, parse JSON, extract "price".

**Column-oriented (DocValues):**
```
title_column:  [doc1→"MacBook", doc2→"ThinkPad", doc3→"Surface"]
price_column:  [doc1→2499, doc2→1299, doc3→1899]
stock_column:  [doc1→50, doc2→120, doc3→30]
rating_column: [doc1→4.8, doc2→4.5, doc3→4.6]
```

To get all prices: Read just the price column!

**Benefits of columnar storage:**
1. **Less I/O**: Only read the columns you need
2. **Better compression**: Same data type = better patterns
3. **CPU vectorization**: SIMD can process 8+ values at once

---

## Global Ordinals (String Aggregations)

### The Challenge of String Aggregations

Numeric aggregations are simple: values are fixed-size, can be compared directly.

String aggregations are hard: strings are variable-length.

**Example: Top 10 brands**

```
Documents:
doc1: {"brand": "Apple"}
doc2: {"brand": "Dell"}
doc3: {"brand": "Apple"}
doc4: {"brand": "HP"}
doc5: {"brand": "Apple"}
```

**Naive approach:**
```
For each doc:
    brand = get_brand(doc)  // String comparison
    counts[brand] += 1      // Hash lookup
    
With 100M docs and 10K brands: Very slow!
```

**Global Ordinals approach:**
```
Build a mapping (once, at refresh time):
  "Apple" → 0
  "Dell"  → 1
  "HP"    → 2
  
Store ordinals per document:
  doc1 → 0
  doc2 → 1
  doc3 → 0
  doc4 → 2
  doc5 → 0

For each doc:
    ordinal = get_ordinal(doc)  // Integer lookup (fast!)
    counts[ordinal] += 1        // Array access (fast!)
    
At the end, map ordinals back to strings.
```

### The Heap Cost of Global Ordinals

**The mapping must be held in memory:**

```
10,000 unique brands
× ~30 bytes per brand name
= 300 KB (no problem)

100,000,000 unique user_ids
× ~36 bytes per UUID
= 3.6 GB of HEAP MEMORY!

This is why high-cardinality text aggregations crash clusters.
```

**Warning signs:**
- Field has millions of unique values
- Aggregation causes heap pressure
- First query after refresh is slow (ordinals being built)

**Solutions:**
1. Use `execution_hint: map` (slower but doesn't use ordinals)
2. Use `composite` aggregation (paginated, low memory)
3. Don't aggregate on high-cardinality fields!

---

## Elasticsearch Mapping Deep Dive

### Choosing the Right Type

```json
{
  "mappings": {
    "properties": {
      // TEXT: Full-text search, analyzed
      "title": { "type": "text", "analyzer": "english" },
      
      // KEYWORD: Exact matches, aggregations
      "category": { "type": "keyword" },
      
      // NUMERIC: Range queries, sorting
      "price": { "type": "float" },
      "quantity": { "type": "integer" },
      
      // DATE: Date math, ranges
      "created_at": { "type": "date" },
      
      // BOOLEAN: True/false filtering
      "in_stock": { "type": "boolean" },
      
      // GEO_POINT: Location queries
      "location": { "type": "geo_point" }
    }
  }
}
```

### Numeric Type Selection

| Type | Bytes | Range | Use For |
|------|-------|-------|---------|
| `byte` | 1 | -128 to 127 | Small enums |
| `short` | 2 | -32K to 32K | Small counts |
| `integer` | 4 | ±2 billion | Most counts |
| `long` | 8 | ±9 quintillion | Timestamps, big IDs |
| `float` | 4 | ±3.4×10³⁸ | Prices (with rounding) |
| `double` | 8 | ±1.7×10³⁰⁸ | Scientific data |
| `scaled_float` | 4 | Depends on scale | Money (no rounding!) |

**Pro tip for money:**
```json
// BAD: Float has precision issues
// 19.99 might become 19.989999771118164

// GOOD: Scaled float
{
  "price": {
    "type": "scaled_float",
    "scaling_factor": 100
  }
}
// 19.99 stored as 1999 (integer), no precision loss
```

### Disabling DocValues (Space Optimization)

```json
{
  "mappings": {
    "properties": {
      "description": {
        "type": "text",
        "doc_values": false  // Can't sort/aggregate on this field
      }
    }
  }
}
```

**When to disable:**
- Text fields you'll NEVER sort or aggregate on
- Save ~30-50% storage for that field

**When NOT to disable:**
- Any field used in sorting
- Any field used in aggregations
- Fields used in script scoring

---

## Geo Queries (BKD in 2D)

### How They Work

```json
// Index
{
  "mappings": {
    "properties": {
      "location": { "type": "geo_point" }
    }
  }
}

// Document
{
  "name": "Starbucks",
  "location": {
    "lat": 37.7749,
    "lon": -122.4194
  }
}
```

**Under the hood:**
```
Lat/Lon stored as two-dimensional BKD tree:

         ┌────────────────────────────────────┐
         │                 │                   │
         │   San Francisco │    East Bay       │
         │                 │                   │
         ├─────────────────┼───────────────────┤
         │                 │                   │
         │   South Bay     │    Mountains      │
         │                 │                   │
         └─────────────────┴───────────────────┘
```

### Query Types

**Distance query: "Within 5km of me"**
```json
{
  "query": {
    "geo_distance": {
      "distance": "5km",
      "location": { "lat": 37.7749, "lon": -122.4194 }
    }
  }
}

Execution:
1. Create bounding box around 5km radius
2. Use BKD tree to find all points in box (FAST)
3. For each point in box, calculate exact distance
4. Filter to actual matches
```

**Bounding box query: "Within this rectangle"**
```json
{
  "query": {
    "geo_bounding_box": {
      "location": {
        "top_left": { "lat": 38.0, "lon": -123.0 },
        "bottom_right": { "lat": 37.5, "lon": -122.0 }
      }
    }
  }
}

Execution:
1. Directly use BKD tree (very efficient)
2. No additional distance calculations
```

---

## Performance Benchmarks

**Dataset: 100 million products**

| Operation | Time |
|-----------|------|
| BKD range query (price 100-200) | 5ms |
| DocValues sort (sort by price) | 50ms |
| Aggregation (avg price) | 100ms |
| Geo distance (within 5km) | 30ms |
| Geo bounding box | 10ms |

**Memory usage:**
```
Numeric field (100M docs):
- BKD tree: ~50 MB
- DocValues: ~400 MB
- Total: ~450 MB

Compare to text field:
- Inverted index: ~2 GB
- (DocValues not supported for analyzed text)
```

---

## Key Takeaways

1. **BKD trees are for range queries** on numeric, date, and geo data. They're O(log N) instead of O(range).

2. **DocValues are for sorting and aggregations**. They store values column-wise for fast access.

3. **Choose numeric types carefully**. Use `scaled_float` for money, `integer` for counts.

4. **Watch out for high-cardinality aggregations**. Global ordinals can consume gigabytes of heap.

5. **Disable DocValues when not needed** to save 30-50% storage.

---

## Forward References

- **[Ch 4.4 Text vs Structured](../data-foundation/4.4-text-vs-structured.md)**: When to use which field type
- **[Ch 5.4 Filters & Facets](../retrieval/5.4-filters.md)**: Using these structures for aggregations
